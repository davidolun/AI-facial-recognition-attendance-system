<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>Webcam Attendance</title>
  
  <!-- Face-api.js for browser-based face recognition -->
  <script src="https://cdn.jsdelivr.net/npm/face-api.js@0.22.2/dist/face-api.min.js"></script>
  
  <style>
    :root { --w: 1200px; }
    body { font-family: system-ui, -apple-system, Segoe UI, Roboto, sans-serif; background:#0b0e13; color:#e5e7eb; margin:0; padding:2rem; }
    h1 { margin: 0 0 1rem; font-size: 1.8rem; font-weight: 600; background: linear-gradient(135deg, #3b82f6, #8b5cf6); -webkit-background-clip: text; -webkit-text-fill-color: transparent; }
    .wrap { max-width: var(--w); margin: 0 auto; }
    
    .nav-links {
      margin-bottom: 1.5rem;
      display: flex;
      gap: 1rem;
      flex-wrap: wrap;
    }
    
    .nav-links a {
      color: #3b82f6;
      text-decoration: none;
      padding: 0.5rem 1rem;
      border-radius: 8px;
      border: 1px solid #374151;
      transition: all 0.2s;
      font-size: 0.9rem;
    }
    
    .nav-links a:hover {
      background: #1f2937;
      border-color: #3b82f6;
    }
    
    .session-control {
      background: #111827;
      border-radius: 12px;
      border: 1px solid #1f2937;
      padding: 1.5rem;
      margin-bottom: 1.5rem;
    }
    
    .session-control h3 {
      margin: 0 0 1rem 0;
      color: #d1d5db;
      font-size: 1.1rem;
    }
    
    .session-select {
      width: 100%;
      padding: 0.75rem;
      background: #1f2937;
      border: 1px solid #374151;
      border-radius: 8px;
      color: #e5e7eb;
      box-sizing: border-box;
      font-size: 0.95rem;
    }
    
    .session-select:focus {
      outline: none;
      border-color: #3b82f6;
    }
    
    .session-select option {
      background: #1f2937;
      color: #e5e7eb;
    }
    
    .session-info {
      margin-top: 1rem;
      padding: 1rem;
      background: #1f2937;
      border-radius: 8px;
      border: 1px solid #374151;
      display: none;
    }
    
    .session-info.active {
      display: block;
    }
    
    .session-info h4 {
      margin: 0 0 0.5rem 0;
      color: #3b82f6;
    }
    
    .session-details {
      display: grid;
      grid-template-columns: 1fr 1fr;
      gap: 1rem;
      font-size: 0.9rem;
    }
    
    .session-details div {
      color: #9ca3af;
    }
    
    .session-details strong {
      color: #e5e7eb;
    }
    
    .attendance-progress {
      margin-top: 1rem;
      background: #111827;
      border-radius: 6px;
      overflow: hidden;
    }
    
    .progress-bar {
      height: 8px;
      background: #3b82f6;
      transition: width 0.3s ease;
    }
    
    .progress-text {
      padding: 0.5rem;
      text-align: center;
      font-size: 0.85rem;
      color: #9ca3af;
    }
    
    .cam { position: relative; width: 100%; aspect-ratio: 16/9; border: 1px solid #1f2937; border-radius: 16px; overflow: hidden; background:#111827; }
    video {
      width: 100%; height: 100%; object-fit: cover;
      transform: scaleX(-1);
    }
    .controls { margin-top: .75rem; display:flex; gap:.5rem; flex-wrap: wrap; }
    button {
      padding: .75rem 1.5rem; border-radius: 10px; border: 1px solid #374151; background: #111827; color:#e5e7eb;
      cursor: pointer; font-weight: 500; transition: all 0.2s;
    }
    button:hover:not(:disabled) {
      background: #1f2937;
      border-color: #3b82f6;
    }
    button:disabled {
      opacity: 0.5;
      cursor: not-allowed;
    }
    .primary-btn {
      background: #3b82f6;
      border-color: #3b82f6;
    }
    .primary-btn:hover:not(:disabled) {
      background: #2563eb;
    }
    .mute-btn {
      background: #6b7280;
      border-color: #6b7280;
      display: flex;
      align-items: center;
      gap: 0.5rem;
    }
    .mute-btn:hover:not(:disabled) {
      background: #4b5563;
      border-color: #4b5563;
    }
    .mute-btn.muted {
      background: #ef4444;
      border-color: #ef4444;
    }
    .mute-btn.muted:hover:not(:disabled) {
      background: #dc2626;
      border-color: #dc2626;
    }
    .status { 
      margin-top:.75rem; 
      padding: 0.75rem;
      border-radius: 10px;
      font-size:.95rem; 
      text-align: center;
    }
    .status.success {
      background: rgba(34, 197, 94, 0.1);
      border: 1px solid rgba(34, 197, 94, 0.3);
      color: #22c55e;
    }
    .status.error {
      background: rgba(239, 68, 68, 0.1);
      border: 1px solid rgba(239, 68, 68, 0.3);
      color: #ef4444;
    }
    .status.info {
      background: rgba(59, 130, 246, 0.1);
      border: 1px solid rgba(59, 130, 246, 0.3);
      color: #3b82f6;
    }
    
    .loading {
      text-align: center;
      color: #9ca3af;
      font-style: italic;
    }
    
    @media (max-width: 600px) {
      .controls {
        flex-direction: column;
      }
      button {
        width: 100%;
      }
      .session-details {
        grid-template-columns: 1fr;
      }
    }
  </style>
</head>
<body>
  <div class="wrap">
    <div class="nav-links">
      {% if user.is_authenticated %}
      <span style="font-size: 1.2rem; font-weight: 600; color: #3b82f6;">Welcome, {{ user.get_full_name }}</span>
      {% endif %}
      <a href="/" style="background: #1f2937; border-color: #3b82f6;">ðŸ“· Take Attendance</a>
      <a href="/add_student/">ðŸ‘¤ Add Student</a>
      <a href="/dashboard/">ðŸ“Š View Records</a>
      <a href="/advanced_analytics/">ðŸ“ˆ Advanced Analytics</a>
      <a href="/class_management/">ðŸ‘¥ Class Management</a>
      <a href="/ai_assistant/">ðŸ¤– AI Assistant</a>
      {% if user.is_authenticated %}
      <a href="/logout/">Logout</a>
{% else %}
      <a href="/login/">Login</a>
      <a href="/signup/">Sign Up</a>
{% endif %}
    </div>
    
    <h1>ðŸ“· Face Recognition Attendance</h1>
    
    <div class="session-control">
      <h3>ðŸ“… Select Session</h3>
      <select id="sessionSelect" class="session-select">
        <option value="">Loading sessions...</option>
      </select>
      
      <div id="sessionInfo" class="session-info">
        <h4 id="selectedSessionName">Session Name</h4>
        <div class="session-details">
          <div><strong>Date:</strong> <span id="sessionDate"></span></div>
          <div><strong>Time:</strong> <span id="sessionTime"></span></div>
          <div><strong>Status:</strong> <span id="sessionStatus"></span></div>
        </div>
        <div class="attendance-progress">
          <div class="progress-bar" id="progressBar" style="width: 0%"></div>
          <div class="progress-text" id="progressText">0 / 0 students attended</div>
        </div>
      </div>
    </div>

    <div class="cam" style="position:relative;">
      <video id="webcam" autoplay playsinline muted style="position:absolute; top:0; left:0; transform: scaleX(-1);"></video>
      <canvas id="overlay" style="position:absolute; top:0; left:0; pointer-events: none; transform: scaleX(-1);"></canvas>
    </div>

    <div class="controls">
      <button id="start" disabled>Start Camera</button>
      <button id="stop" disabled>Stop Camera</button>
      <button id="capture" class="primary-btn" disabled>ðŸ“‹ Take Attendance</button>
      <button id="muteBtn" class="mute-btn" title="Toggle Voice Announcements">
        <span id="muteIcon">ðŸ”Š</span>
        <span id="muteText">Mute</span>
      </button>
    </div>

    <div id="status" class="status info">Please select a session first</div>
    <canvas id="canvas" style="display:none;"></canvas>
  </div>

  <script>
const video = document.getElementById('webcam');
const overlay = document.getElementById('overlay');
const overlayCtx = overlay.getContext('2d');
const canvas = document.getElementById('canvas');
const startBtn = document.getElementById('start');
const stopBtn  = document.getElementById('stop');
const captureBtn = document.getElementById('capture');
const statusEl = document.getElementById('status');
const sessionSelect = document.getElementById('sessionSelect');
const muteBtn = document.getElementById('muteBtn');
const muteIcon = document.getElementById('muteIcon');
const muteText = document.getElementById('muteText');

// Face-api.js initialization
let faceApiLoaded = false;
let faceDetectionModel = null;

async function initializeFaceApi() {
    try {
        // Load face detection models
        await faceapi.nets.tinyFaceDetector.loadFromUri('https://cdn.jsdelivr.net/npm/face-api.js@0.22.2/weights');
        await faceapi.nets.faceLandmark68Net.loadFromUri('https://cdn.jsdelivr.net/npm/face-api.js@0.22.2/weights');
        await faceapi.nets.faceRecognitionNet.loadFromUri('https://cdn.jsdelivr.net/npm/face-api.js@0.22.2/weights');
        
        faceApiLoaded = true;
        console.log('Face-api.js loaded successfully');
    } catch (error) {
        console.error('Failed to load face-api.js models:', error);
        faceApiLoaded = false;
    }
}

// Initialize face-api.js when page loads
initializeFaceApi();

// Text-to-speech functionality
let isMuted = false;
let speechSynthesis = window.speechSynthesis;
const sessionInfo = document.getElementById('sessionInfo');

// Function to speak attendance announcements
function speakAttendance(message) {
    if (isMuted || !speechSynthesis) {
        console.log('TTS blocked:', { isMuted, speechSynthesis: !!speechSynthesis });
        return;
    }
    
    console.log('Speaking:', message);
    
    // Stop any current speech
    speechSynthesis.cancel();
    
    const utterance = new SpeechSynthesisUtterance(message);
    utterance.rate = 0.9;
    utterance.pitch = 1.0;
    utterance.volume = 0.8;
    
    // Wait for voices to load if they haven't loaded yet
    const speak = () => {
        const voices = speechSynthesis.getVoices();
        console.log('Available voices:', voices.length);
        
        // Try to use a more natural voice if available
        const preferredVoice = voices.find(voice => 
            voice.lang.startsWith('en') && 
            (voice.name.includes('Google') || voice.name.includes('Microsoft') || voice.name.includes('Samantha'))
        );
        
        if (preferredVoice) {
            utterance.voice = preferredVoice;
            console.log('Using voice:', preferredVoice.name);
        }
        
        speechSynthesis.speak(utterance);
    };
    
    // If voices are already loaded, speak immediately
    if (speechSynthesis.getVoices().length > 0) {
        speak();
    } else {
        // Wait for voices to load
        speechSynthesis.addEventListener('voiceschanged', speak, { once: true });
    }
}

// Toggle mute functionality
function toggleMute() {
    isMuted = !isMuted;
    
    if (isMuted) {
        muteIcon.textContent = 'ðŸ”‡';
        muteText.textContent = 'Unmute';
        muteBtn.classList.add('muted');
        // Stop any current speech
        speechSynthesis.cancel();
    } else {
        muteIcon.textContent = 'ðŸ”Š';
        muteText.textContent = 'Mute';
        muteBtn.classList.remove('muted');
    }
}

// Add event listeners
muteBtn.addEventListener('click', toggleMute);

// Initialize TTS on page load
document.addEventListener('DOMContentLoaded', function() {
    // Load voices immediately
    if (speechSynthesis.getVoices().length === 0) {
        speechSynthesis.addEventListener('voiceschanged', function() {
            console.log('Voices loaded:', speechSynthesis.getVoices().length);
        }, { once: true });
    }
    
    // Test TTS availability
    console.log('Speech synthesis available:', !!speechSynthesis);
    console.log('Initial voices count:', speechSynthesis.getVoices().length);
});

let stream;
let faceData = [];
let selectedSession = null;
let sessions = [];
let faceDetectionInterval;

// Load sessions on page load
async function loadSessions() {
    try {
        const response = await fetch('/get_sessions/');
        const data = await response.json();
        
        if (data.sessions) {
            sessions = data.sessions;
            populateSessionSelect();
        } else {
            sessionSelect.innerHTML = '<option value="">No sessions available</option>';
            statusEl.textContent = 'No sessions found. Please create sessions first.';
            statusEl.className = 'status error';
        }
    } catch (error) {
        console.error('Error loading sessions:', error);
        sessionSelect.innerHTML = '<option value="">Error loading sessions</option>';
        statusEl.textContent = 'Error loading sessions';
        statusEl.className = 'status error';
    }
}

function populateSessionSelect() {
    sessionSelect.innerHTML = '<option value="">Select a session...</option>';
    
    // Group sessions by date
    const today = new Date().toDateString();
    const todaySessions = sessions.filter(s => new Date(s.date).toDateString() === today);
    const upcomingSessions = sessions.filter(s => new Date(s.date).toDateString() !== today);
    
    if (todaySessions.length > 0) {
        const todayGroup = document.createElement('optgroup');
        todayGroup.label = 'Today';
        todaySessions.forEach(session => {
            const option = document.createElement('option');
            option.value = session.id;
            option.textContent = `${session.name} (${session.start_time} - ${session.end_time})`;
            todayGroup.appendChild(option);
        });
        sessionSelect.appendChild(todayGroup);
    }
    
    if (upcomingSessions.length > 0) {
        const upcomingGroup = document.createElement('optgroup');
        upcomingGroup.label = 'Upcoming';
        upcomingSessions.forEach(session => {
            const option = document.createElement('option');
            option.value = session.id;
            option.textContent = `${session.name} - ${session.date_display} (${session.start_time})`;
            upcomingGroup.appendChild(option);
        });
        sessionSelect.appendChild(upcomingGroup);
    }
}

function updateSessionInfo() {
    const sessionId = sessionSelect.value;
    if (!sessionId) {
        sessionInfo.classList.remove('active');
        startBtn.disabled = true;
        statusEl.textContent = 'Please select a session first';
        statusEl.className = 'status info';
        selectedSession = null;
        return;
    }
    
    selectedSession = sessions.find(s => s.id == sessionId);
    if (!selectedSession) return;
    
    // Update session info display
    document.getElementById('selectedSessionName').textContent = selectedSession.name;
    document.getElementById('sessionDate').textContent = selectedSession.date_display;
    document.getElementById('sessionTime').textContent = `${selectedSession.start_time} - ${selectedSession.end_time}`;
    document.getElementById('sessionStatus').textContent = selectedSession.status;
    
    // Update progress
    const progressPercent = selectedSession.total_students > 0 
        ? (selectedSession.attendance_count / selectedSession.total_students) * 100 
        : 0;
    document.getElementById('progressBar').style.width = progressPercent + '%';
    document.getElementById('progressText').textContent = 
        `${selectedSession.attendance_count} / ${selectedSession.total_students} students attended`;
    
    sessionInfo.classList.add('active');
    startBtn.disabled = false;
    statusEl.textContent = 'Session selected. Click "Start Camera" to begin attendance';
    statusEl.className = 'status success';
}

// Start camera
async function startCamera() {
    if (!selectedSession) {
        statusEl.textContent = 'Please select a session first';
        statusEl.className = 'status error';
        return;
    }
    
    try {
        statusEl.textContent = 'Starting cameraâ€¦';
        statusEl.className = 'status info';
        
        stream = await navigator.mediaDevices.getUserMedia({
            video: { width: {ideal:1280}, height:{ideal:720} },
            audio: false
        });
        video.srcObject = stream;
        await video.play();
        statusEl.textContent = `Camera is live for ${selectedSession.name}. Face detection active.`;
        statusEl.className = 'status success';
        startBtn.disabled = true;
        stopBtn.disabled  = false;
        captureBtn.disabled = false;

        resizeOverlay();
        startFaceDetection();
    } catch (err) {
        console.error(err);
        statusEl.textContent = 'Error: ' + (err.message || err.name);
        statusEl.className = 'status error';
    }
}

function resizeOverlay() {
    const rect = video.getBoundingClientRect();
    overlay.width = rect.width;
    overlay.height = rect.height;
    overlay.style.width = rect.width + 'px';
    overlay.style.height = rect.height + 'px';
}

function stopCamera() {
    if (stream) {
        stream.getTracks().forEach(t => t.stop());
        video.srcObject = null;
    }
    
    // Stop face detection
    if (faceDetectionInterval) {
        clearInterval(faceDetectionInterval);
        faceDetectionInterval = null;
    }
    
    // Clear overlay
    overlayCtx.clearRect(0, 0, overlay.width, overlay.height);
    
    statusEl.textContent = 'Camera stopped.';
    statusEl.className = 'status info';
    startBtn.disabled = false;
    stopBtn.disabled = true;
    captureBtn.disabled = true;
}

function startFaceDetection() {
    if (!faceApiLoaded) return;
    
    faceDetectionInterval = setInterval(async () => {
        if (video.readyState === video.HAVE_ENOUGH_DATA) {
            try {
                const detections = await faceapi
                    .detectAllFaces(video, new faceapi.TinyFaceDetectorOptions())
                    .withFaceLandmarks()
                    .withFaceDescriptors();
                
                drawFaceBoxes(detections);
            } catch (error) {
                console.error('Face detection error:', error);
            }
        }
    }, 100);
}

function drawFaceBoxes(detections) {
    overlayCtx.clearRect(0, 0, overlay.width, overlay.height);
    
    if (detections.length === 0) return;
    
    const scaleX = overlay.width / video.videoWidth;
    const scaleY = overlay.height / video.videoHeight;
    
    detections.forEach(detection => {
        const { x, y, width, height } = detection.detection.box;
        
        overlayCtx.strokeStyle = '#22c55e';
        overlayCtx.lineWidth = 3;
        overlayCtx.strokeRect(x * scaleX, y * scaleY, width * scaleX, height * scaleY);
        
        // Draw face label
        overlayCtx.fillStyle = '#22c55e';
        overlayCtx.font = '16px Arial';
        overlayCtx.fillText('Face Detected', x * scaleX, y * scaleY - 5);
    });
}


// Face detection and embedding functions
async function detectFacesAndGetEmbeddings(imageElement) {
    if (!faceApiLoaded) {
        throw new Error('Face-api.js not loaded yet');
    }
    
    try {
        // Detect faces and get descriptors (embeddings)
        const detections = await faceapi
            .detectAllFaces(imageElement, new faceapi.TinyFaceDetectorOptions())
            .withFaceLandmarks()
            .withFaceDescriptors();
        
        return detections.map(detection => ({
            detection: detection.detection,
            descriptor: Array.from(detection.descriptor) // Convert Float32Array to regular array
        }));
    } catch (error) {
        console.error('Face detection error:', error);
        throw error;
    }
}

async function getFaceEmbeddingFromVideo() {
    if (!faceApiLoaded) {
        throw new Error('Face-api.js not loaded yet');
    }
    
    // Create a temporary canvas to capture current video frame
    const tempCanvas = document.createElement('canvas');
    tempCanvas.width = video.videoWidth;
    tempCanvas.height = video.videoHeight;
    const tempCtx = tempCanvas.getContext('2d');
    tempCtx.drawImage(video, 0, 0);
    
    // Convert canvas to image element for face-api.js
    const imageElement = new Image();
    imageElement.src = tempCanvas.toDataURL();
    
    return new Promise((resolve, reject) => {
        imageElement.onload = async () => {
            try {
                const faces = await detectFacesAndGetEmbeddings(imageElement);
                if (faces.length === 0) {
                    reject(new Error('No faces detected'));
                } else if (faces.length > 1) {
                    reject(new Error('Multiple faces detected. Please ensure only one person is in the frame.'));
                } else {
                    resolve(faces[0].descriptor);
                }
            } catch (error) {
                reject(error);
            }
        };
        imageElement.onerror = () => reject(new Error('Failed to load image'));
    });
}

async function captureFrame() {
    if (!selectedSession) {
        statusEl.textContent = 'Please select a session first';
        statusEl.className = 'status error';
        return;
    }
    
    if (!faceApiLoaded) {
        statusEl.textContent = 'Face recognition still loading...';
        statusEl.className = 'status error';
        return;
    }
    
    statusEl.textContent = 'Processing attendance...';
    statusEl.className = 'status info';
    captureBtn.disabled = true;

    try {
        // Get face embedding from current video frame
        const faceEmbedding = await getFaceEmbeddingFromVideo();
        
        // Send embedding to server for matching
        const response = await fetch("/take_attendance_with_embedding/", {
            method: "POST",
            headers: {
                "Content-Type": "application/json",
                "X-CSRFToken": getCookie("csrftoken"),
            },
            body: JSON.stringify({ 
                face_embedding: faceEmbedding,
                session_id: selectedSession.id
            })
        });
        
        const data = await response.json();
        
        if (data.error) {
            statusEl.textContent = "Error: " + data.error;
            statusEl.className = 'status error';
            speakAttendance("Error taking attendance");
        } else {
            statusEl.textContent = data.message;
            statusEl.className = 'status success';
            
            // Extract student names from the message for TTS
            const message = data.message;
            if (message.includes("Attendance taken:")) {
                const studentsText = message.replace("Attendance taken: ", "");
                if (studentsText === "No match") {
                    speakAttendance("No students recognized");
                } else {
                    // Parse individual student names and announce each
                    const students = studentsText.split(", ");
                    students.forEach((student, index) => {
                        // Remove status info like "(On time - 10:30:15)" and just get the name
                        const studentName = student.split(" (")[0];
                        setTimeout(() => {
                            speakAttendance(`Attendance taken for ${studentName}`);
                        }, index * 1000); // Stagger announcements by 1 second
                    });
                }
            }
            
            // Also try a simple test to ensure TTS is working
            setTimeout(() => {
                if (!isMuted) {
                    speakAttendance("Attendance recorded");
                }
            }, 500);
            
            // Update progress display
            if (data.attendance_count !== undefined) {
                const progressPercent = data.total_students > 0 
                    ? (data.attendance_count / data.total_students) * 100 
                    : 0;
                document.getElementById('progressBar').style.width = progressPercent + '%';
                document.getElementById('progressText').textContent = 
                    `${data.attendance_count} / ${data.total_students} students attended`;
                    
                // Update selected session data
                selectedSession.attendance_count = data.attendance_count;
            }
        }
    } catch (error) {
        if (error.message.includes('No faces detected')) {
            statusEl.textContent = 'No face detected. Please ensure your face is visible.';
        } else if (error.message.includes('Multiple faces detected')) {
            statusEl.textContent = 'Multiple faces detected. Please ensure only one person is in the frame.';
        } else if (error.message.includes('Face-api.js not loaded')) {
            statusEl.textContent = 'Face recognition still loading. Please wait...';
        } else {
            statusEl.textContent = "Error: " + error.message;
        }
        statusEl.className = 'status error';
        speakAttendance("Error taking attendance");
    } finally {
        captureBtn.disabled = false;
    }
}

function getCookie(name) {
    let cookieValue = null;
    if (document.cookie && document.cookie !== "") {
        const cookies = document.cookie.split(";");
        for (let cookie of cookies) {
            cookie = cookie.trim();
            if (cookie.startsWith(name + "=")) {
                cookieValue = decodeURIComponent(cookie.substring(name.length + 1));
                break;
            }
        }
    }
    return cookieValue;
}

// Event listeners
sessionSelect.addEventListener('change', updateSessionInfo);
startBtn.addEventListener('click', startCamera);
stopBtn.addEventListener('click', stopCamera);
captureBtn.addEventListener('click', captureFrame);
window.addEventListener('resize', resizeOverlay);

// Initialize
loadSessions();
</script>

</body>
</html>